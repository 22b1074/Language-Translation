{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "912e4ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         translation\n",
      "0  {'en': 'A black box in your car?', 'hi': 'आपकी...\n",
      "1  {'en': 'As America's road planners struggle to...\n",
      "2  {'en': 'The devices, which track every mile a ...\n",
      "3  {'en': 'The usually dull arena of highway plan...\n",
      "4  {'en': 'Libertarians have joined environmental...\n",
      "5  {'en': 'The tea party is aghast.', 'hi': 'चाय ...\n",
      "6  {'en': 'The American Civil Liberties Union is ...\n",
      "7  {'en': 'And while Congress can't agree on whet...\n",
      "8  {'en': 'They are exploring how, over the next ...\n",
      "9  {'en': 'Thousands of motorists have already ta...\n",
      "['translation']\n",
      "                                         translation\n",
      "0  {'en': 'Give your application an accessibility...\n",
      "1  {'en': 'Accerciser Accessibility Explorer', 'h...\n",
      "2  {'en': 'The default plugin layout for the bott...\n",
      "3  {'en': 'The default plugin layout for the top ...\n",
      "4  {'en': 'A list of plugins that are disabled by...\n",
      "5  {'en': 'Highlight duration', 'hi': 'अवधि को हा...\n",
      "6  {'en': 'The duration of the highlight box when...\n",
      "7  {'en': 'Highlight border color', 'hi': 'सीमांत...\n",
      "8  {'en': 'The color and opacity of the highlight...\n",
      "9  {'en': 'Highlight fill color', 'hi': 'भराई के ...\n",
      "['translation']\n",
      "                                         translation\n",
      "0  {'en': 'Students of the Dattatreya city Munici...\n",
      "1  {'en': 'With encouragement from Principal Sand...\n",
      "2  {'en': 'Rajesh Gavre, the President of the MNP...\n",
      "3  {'en': 'Ramesh Saatpute examined the fort.', '...\n",
      "4  {'en': 'Students like Nikhil Kavle, Darshan Ge...\n",
      "5  {'en': 'Narender Barai, the President of the D...\n",
      "6  {'en': 'Nagarsevak, Reeta Mule presented messa...\n",
      "7  {'en': 'Rohtak. Akhil Bhartiya Janwadi Mahila ...\n",
      "8  {'en': 'Through this state-wide signature camp...\n",
      "9  {'en': 'The signature campaign started on Frid...\n",
      "['translation']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace 'your_file.parquet' with your file path\n",
    "df = pd.read_parquet('test_lang.parquet')\n",
    "\n",
    "# Preview the data\n",
    "print(df.head(10))\n",
    "print(df.columns.tolist())\n",
    "# Split training data\n",
    "with open('test_en', 'w', encoding='utf-8') as f_en, \\\n",
    "     open('test_hi', 'w', encoding='utf-8') as f_hi:\n",
    "    for _, row in df.iterrows():\n",
    "        f_en.write(row['translation']['en'] + '\\n')\n",
    "        f_hi.write(row['translation']['hi'] + '\\n')\n",
    "\n",
    "# Replace 'your_file.parquet' with your file path\n",
    "df = pd.read_parquet('train_lang.parquet')\n",
    "\n",
    "# Preview the data\n",
    "print(df.head(10))\n",
    "print(df.columns.tolist())\n",
    "# Split training data\n",
    "with open('train_en', 'w', encoding='utf-8') as f_en, \\\n",
    "     open('train_hi', 'w', encoding='utf-8') as f_hi:\n",
    "    for _, row in df.iterrows():\n",
    "        f_en.write(row['translation']['en'] + '\\n')\n",
    "        f_hi.write(row['translation']['hi'] + '\\n')\n",
    "\n",
    "# Replace 'your_file.parquet' with your file path\n",
    "df = pd.read_parquet('val_lang.parquet')\n",
    "\n",
    "# Preview the data\n",
    "print(df.head(10))\n",
    "print(df.columns.tolist())\n",
    "# Split training data\n",
    "with open('val_en', 'w', encoding='utf-8') as f_en, \\\n",
    "     open('val_hi', 'w', encoding='utf-8') as f_hi:\n",
    "    for _, row in df.iterrows():\n",
    "        f_en.write(row['translation']['en'] + '\\n')\n",
    "        f_hi.write(row['translation']['hi'] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67c6d02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./hindi_bpe-vocab.json', './hindi_bpe-merges.txt']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tokenizers import ByteLevelBPETokenizer\n",
    "en_tokenizer = ByteLevelBPETokenizer()\n",
    "en_tokenizer.train(\n",
    "    files=['train_en', 'test_en', 'val_en'],\n",
    "    vocab_size=10000,\n",
    "    min_frequency=2,\n",
    "    special_tokens=['[PAD]', '[SOS]', '[EOS]', '[UNK]']\n",
    ")\n",
    "en_tokenizer.save_model('.', 'english_bpe')\n",
    "\n",
    "# 4. Train Hindi BPE Tokenizer (handles Devanagari script)\n",
    "hi_tokenizer = ByteLevelBPETokenizer()\n",
    "hi_tokenizer.train(\n",
    "    files=['train_hi', 'test_hi', 'val_hi'],\n",
    "    vocab_size=15000,  # Larger vocab for Hindi's richer morphology\n",
    "    min_frequency=2,\n",
    "    special_tokens=['[PAD]', '[SOS]', '[EOS]', '[UNK]']\n",
    ")\n",
    "hi_tokenizer.save_model('.', 'hindi_bpe')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2375a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import ByteLevelBPETokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d60c8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved tokenizers\n",
    "en_tokenizer = ByteLevelBPETokenizer(\n",
    "    'english_bpe-vocab.json',\n",
    "    'english_bpe-merges.txt'\n",
    ")\n",
    "hi_tokenizer = ByteLevelBPETokenizer(\n",
    "    'hindi_bpe-vocab.json',\n",
    "    'hindi_bpe-merges.txt'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d743ed32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "# Custom Multi-Head Attention\n",
    "class CustomMultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, nhead, dropout=0.15):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.nhead = nhead\n",
    "        self.dropout = dropout\n",
    "        self.head_dim = d_model // nhead\n",
    "\n",
    "        assert d_model % nhead == 0,  \"d_model must be divisible by nhead\"\n",
    "\n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.out_linear = nn.Linear(d_model, d_model)\n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        B, T_q, _ = query.size()\n",
    "        B, T_k, _ = key.size()\n",
    "        B, T_v, _ = value.size()\n",
    "\n",
    "        Q = self.q_linear(query).view(B, T_q, self.nhead, self.head_dim).transpose(1, 2)\n",
    "        K = self.k_linear(key).view(B, T_k, self.nhead, self.head_dim).transpose(1, 2)\n",
    "        V = self.v_linear(value).view(B, T_v, self.nhead, self.head_dim).transpose(1, 2)\n",
    "        #print(f\"Q shape: {Q.shape}, K shape: {K.shape}, V shape: {V.shape}\")\n",
    "\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
    "        if mask is not None:\n",
    "            #mask = mask.unsqueeze(1).unsqueeze(2)\n",
    "            scores = scores.masked_fill(mask == 0, -float('inf'))\n",
    "\n",
    "        attn = F.softmax(scores, dim=-1)\n",
    "        attn = self.dropout_layer(attn)\n",
    "        #print(f\"Attn Shape: {attn.shape}\")\n",
    "        output = torch.matmul(attn, V)\n",
    "        #print(f\"output.shape: {output.shape}\")\n",
    "        #print(f\"B: {B}, T_Q: {T_q}, T_K: {T_k}, T_V: {T_v}, d_model: {self.d_model}\")\n",
    "\n",
    "        output = output.transpose(1, 2).contiguous().view(B, T_q, self.d_model)\n",
    "        return self.out_linear(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff3c750f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear2(self.dropout(F.relu(self.linear1(x))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c42377e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = CustomMultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src, src_mask):\n",
    "        src2 = self.self_attn(src, src, src, src_mask)\n",
    "        src = self.norm1(src + self.dropout(src2))\n",
    "        src2 = self.ffn(src)\n",
    "        src = self.norm2(src + self.dropout(src2))\n",
    "        return src\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = CustomMultiHeadAttention(d_model, num_heads)\n",
    "        self.cross_attn = CustomMultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, tgt, memory, tgt_mask, memory_mask):\n",
    "        tgt2 = self.self_attn(tgt, tgt, tgt, tgt_mask)\n",
    "        tgt = self.norm1(tgt + self.dropout(tgt2))\n",
    "        tgt2 = self.cross_attn(tgt, memory, memory, memory_mask)\n",
    "        tgt = self.norm2(tgt + self.dropout(tgt2))\n",
    "        tgt2 = self.ffn(tgt)\n",
    "        tgt = self.norm3(tgt + self.dropout(tgt2))\n",
    "        return tgt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9e3cddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(1)]\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "476491e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, num_layers, num_heads, d_ff, dropout=0.1, max_len=512):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_enc = PositionalEncoding(d_model, max_len)\n",
    "        self.layers = nn.ModuleList([\n",
    "            EncoderLayer(d_model, num_heads, d_ff, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, src, src_mask):\n",
    "        x = self.embed(src)\n",
    "        x = self.pos_enc(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, src_mask)\n",
    "        return x\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, num_layers, num_heads, d_ff, dropout=0.1, max_len=512):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_enc = PositionalEncoding(d_model, max_len)\n",
    "        self.layers = nn.ModuleList([\n",
    "            DecoderLayer(d_model, num_heads, d_ff, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, tgt, memory, tgt_mask, memory_mask):\n",
    "        x = self.embed(tgt)\n",
    "        x = self.pos_enc(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory, tgt_mask, memory_mask)\n",
    "        return self.fc_out(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3adec487",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model=256, num_layers=4, num_heads=4, d_ff=1024, dropout=0.1, max_len=512):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(src_vocab_size, d_model, num_layers, num_heads, d_ff, dropout, max_len)\n",
    "        self.decoder = Decoder(tgt_vocab_size, d_model, num_layers, num_heads, d_ff, dropout, max_len)\n",
    "\n",
    "    def make_src_mask(self, src, pad_token_id):\n",
    "        return (src != pad_token_id).unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "    def make_tgt_mask(self, tgt, pad_token_id):\n",
    "        batch_size, tgt_len = tgt.shape\n",
    "        tgt_mask = (tgt != pad_token_id).unsqueeze(1).unsqueeze(2)\n",
    "        nopeak_mask = torch.tril(torch.ones((tgt_len, tgt_len), device=tgt.device)).bool().unsqueeze(0).unsqueeze(0)\n",
    "        return tgt_mask & nopeak_mask\n",
    "\n",
    "    def forward(self, src, tgt_input, src_mask, tgt_mask):\n",
    "        memory = self.encoder(src, src_mask)\n",
    "        output = self.decoder(tgt_input, memory, tgt_mask, src_mask)\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400cfec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Params\n",
    "batch_size = 64        \n",
    "num_epochs = 25        # for testing\n",
    "learning_rate = 0.01 # Adam optimizer\n",
    "dropout = 0.15          # Regularization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4101b44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import random\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, parquet_path, en_tokenizer, hi_tokenizer, max_length=128):\n",
    "        self.df = pd.read_parquet(parquet_path)\n",
    "        self.en_tok = en_tokenizer\n",
    "        self.hi_tok = hi_tokenizer\n",
    "        self.max_len = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        translation = self.df.iloc[idx]['translation']\n",
    "        en_text = translation['en']\n",
    "        hi_text = translation['hi']\n",
    "        \n",
    "        # Tokenize with special tokens\n",
    "        en_ids = [self.en_tok.token_to_id('[SOS]')] \\\n",
    "                + self.en_tok.encode(en_text).ids[:self.max_len-2] \\\n",
    "                + [self.en_tok.token_to_id('[EOS]')]\n",
    "        \n",
    "        hi_ids = [self.hi_tok.token_to_id('[SOS]')] \\\n",
    "                + self.hi_tok.encode(hi_text).ids[:self.max_len-2] \\\n",
    "                + [self.hi_tok.token_to_id('[EOS]')]\n",
    "\n",
    "        # Pad sequences\n",
    "        en_padded = en_ids + [self.en_tok.token_to_id('[PAD]')]*(self.max_len - len(en_ids))\n",
    "        hi_padded = hi_ids + [self.hi_tok.token_to_id('[PAD]')]*(self.max_len - len(hi_ids))\n",
    "        \n",
    "        return {\n",
    "            'en': torch.tensor(en_padded, dtype=torch.long),\n",
    "            'hi': torch.tensor(hi_padded, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Full train dataset\n",
    "full_train_dataset = TranslationDataset('train_lang.parquet', en_tokenizer, hi_tokenizer)\n",
    "\n",
    "# select only some dataset to check working\n",
    "total_len = len(full_train_dataset)\n",
    "sample_size = int(100)\n",
    "subset_train_indices = random.sample(range(total_len), sample_size)\n",
    "\n",
    "# Create subset dataset\n",
    "train_dataset = Subset(full_train_dataset, subset_train_indices)\n",
    "full_val_dataset = TranslationDataset('val_lang.parquet', en_tokenizer, hi_tokenizer)\n",
    "\n",
    "val_len = len(full_val_dataset)\n",
    "subset_val_indices = random.sample(range(val_len), sample_size)\n",
    "val_dataset = Subset(full_val_dataset, subset_val_indices)\n",
    "def collate_fn(batch):\n",
    "    # Convert list of dicts to tensor tuples\n",
    "    en = torch.stack([item['en'] for item in batch])\n",
    "    hi = torch.stack([item['hi'] for item in batch])\n",
    "    return en, hi\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn  \n",
    ")\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=32,collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffe746c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(src_vocab_size=10000, tgt_vocab_size=15000)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bfeaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 | Train Loss: 7.3572, Train Acc: 5.59% | Val Loss: 5.6909, Val Acc: 1.50%\n",
      "✅ Best model saved.\n",
      "Epoch 2/25 | Train Loss: 5.1104, Train Acc: 4.84% | Val Loss: 5.7439, Val Acc: 5.91%\n",
      "Epoch 3/25 | Train Loss: 4.8737, Train Acc: 5.73% | Val Loss: 5.9189, Val Acc: 5.16%\n",
      "Epoch 4/25 | Train Loss: 4.9572, Train Acc: 6.19% | Val Loss: 5.9260, Val Acc: 9.61%\n",
      "Epoch 5/25 | Train Loss: 4.9317, Train Acc: 6.50% | Val Loss: 5.9521, Val Acc: 5.16%\n",
      "Epoch 6/25 | Train Loss: 4.7614, Train Acc: 5.95% | Val Loss: 5.8725, Val Acc: 9.61%\n",
      "Epoch 7/25 | Train Loss: 4.8107, Train Acc: 8.24% | Val Loss: 5.8276, Val Acc: 5.16%\n",
      "Epoch 8/25 | Train Loss: 4.7606, Train Acc: 6.31% | Val Loss: 5.7401, Val Acc: 9.61%\n",
      "Epoch 9/25 | Train Loss: 4.6922, Train Acc: 8.11% | Val Loss: 5.7251, Val Acc: 9.61%\n",
      "Epoch 10/25 | Train Loss: 4.7596, Train Acc: 7.95% | Val Loss: 5.6601, Val Acc: 9.61%\n",
      "✅ Best model saved.\n",
      "Epoch 11/25 | Train Loss: 4.6858, Train Acc: 7.99% | Val Loss: 5.5932, Val Acc: 9.61%\n",
      "✅ Best model saved.\n",
      "Epoch 12/25 | Train Loss: 4.7072, Train Acc: 8.33% | Val Loss: 5.5621, Val Acc: 5.16%\n",
      "✅ Best model saved.\n",
      "Epoch 13/25 | Train Loss: 4.7305, Train Acc: 5.56% | Val Loss: 5.4826, Val Acc: 9.61%\n",
      "✅ Best model saved.\n",
      "Epoch 14/25 | Train Loss: 4.7171, Train Acc: 8.21% | Val Loss: 5.4186, Val Acc: 9.61%\n",
      "✅ Best model saved.\n",
      "Epoch 15/25 | Train Loss: 4.6255, Train Acc: 7.54% | Val Loss: 5.3945, Val Acc: 5.16%\n",
      "✅ Best model saved.\n",
      "Epoch 16/25 | Train Loss: 4.7323, Train Acc: 5.44% | Val Loss: 5.3972, Val Acc: 9.61%\n",
      "Epoch 17/25 | Train Loss: 4.7567, Train Acc: 8.28% | Val Loss: 5.3558, Val Acc: 9.61%\n",
      "✅ Best model saved.\n",
      "Epoch 18/25 | Train Loss: 4.7363, Train Acc: 7.13% | Val Loss: 5.3122, Val Acc: 5.16%\n",
      "✅ Best model saved.\n",
      "Epoch 19/25 | Train Loss: 4.6509, Train Acc: 6.65% | Val Loss: 5.2841, Val Acc: 9.61%\n",
      "✅ Best model saved.\n",
      "Epoch 20/25 | Train Loss: 4.7392, Train Acc: 8.28% | Val Loss: 5.2867, Val Acc: 9.61%\n",
      "Epoch 21/25 | Train Loss: 4.6612, Train Acc: 8.09% | Val Loss: 5.2736, Val Acc: 9.61%\n",
      "✅ Best model saved.\n",
      "Epoch 22/25 | Train Loss: 4.6815, Train Acc: 8.21% | Val Loss: 5.2610, Val Acc: 9.61%\n",
      "✅ Best model saved.\n",
      "Epoch 23/25 | Train Loss: 4.7023, Train Acc: 8.31% | Val Loss: 5.2547, Val Acc: 9.61%\n",
      "✅ Best model saved.\n",
      "Epoch 24/25 | Train Loss: 4.6659, Train Acc: 8.28% | Val Loss: 5.2684, Val Acc: 9.61%\n",
      "Epoch 25/25 | Train Loss: 4.6818, Train Acc: 8.28% | Val Loss: 5.2530, Val Acc: 9.61%\n",
      "✅ Best model saved.\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "best_val_loss = float('inf')\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    for src, tgt in train_loader:\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "        \n",
    "        # Teacher forcing preparation\n",
    "        tgt_input = tgt[:, :-1]\n",
    "        tgt_output = tgt[:, 1:]\n",
    "        \n",
    "        # Mask creation\n",
    "        src_mask = model.make_src_mask(src, en_tokenizer.token_to_id(\"[PAD]\"))\n",
    "        tgt_mask = model.make_tgt_mask(tgt_input, hi_tokenizer.token_to_id(\"[PAD]\"))\n",
    "        \n",
    "        # Forward pass\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask)\n",
    "        \n",
    "        # Loss \n",
    "        loss = F.cross_entropy(\n",
    "            logits.view(-1, logits.size(-1)),\n",
    "            tgt_output.reshape(-1),\n",
    "            ignore_index=hi_tokenizer.token_to_id(\"[PAD]\")\n",
    "        )\n",
    "        \n",
    "        # backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Accuracy\n",
    "        preds = logits.argmax(dim=-1)\n",
    "        mask = tgt_output != hi_tokenizer.token_to_id(\"[PAD]\")\n",
    "        train_correct += (preds[mask] == tgt_output[mask]).sum().item()\n",
    "        train_total += mask.sum().item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_acc = train_correct / train_total\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in val_loader:\n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "\n",
    "            tgt_input = tgt[:, :-1]\n",
    "            tgt_output = tgt[:, 1:]\n",
    "\n",
    "            src_mask = model.make_src_mask(src, en_tokenizer.token_to_id(\"[PAD]\"))\n",
    "            tgt_mask = model.make_tgt_mask(tgt_input, hi_tokenizer.token_to_id(\"[PAD]\"))\n",
    "\n",
    "            logits = model(src, tgt_input, src_mask, tgt_mask)\n",
    "\n",
    "            loss = F.cross_entropy(\n",
    "                logits.view(-1, logits.size(-1)),\n",
    "                tgt_output.reshape(-1),\n",
    "                ignore_index=hi_tokenizer.token_to_id(\"[PAD]\")\n",
    "            )\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            preds = logits.argmax(dim=-1)\n",
    "            mask = tgt_output != hi_tokenizer.token_to_id(\"[PAD]\")\n",
    "            val_correct += (preds[mask] == tgt_output[mask]).sum().item()\n",
    "            val_total += mask.sum().item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_acc = val_correct / val_total\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc*100:.2f}% | \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc*100:.2f}%\")\n",
    "\n",
    "    # Save the best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        print(\"✅ Best model saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
